{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96ffd791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Embedding,\n",
    "    LSTM,\n",
    "    Bidirectional,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    SpatialDropout1D,\n",
    "    BatchNormalization,\n",
    ")\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1dde0e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69426b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_df = pd.read_csv(\"../data/train_data.csv\")\n",
    "valid_df = pd.read_csv(\"../data/valid_data.csv\")\n",
    "\n",
    "train_df[\"text\"] = train_df[\"text\"].fillna(\"\")\n",
    "valid_df[\"text\"] = valid_df[\"text\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b958798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text cleaning (same behavior as original)\n",
    "def clean_financial_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    # URLs\n",
    "    text = re.sub(r\"http\\S+|www\\.\\S+|https\\S+\", \"\", text)\n",
    "\n",
    "    # Mentions\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "\n",
    "    # HTML entities\n",
    "    text = re.sub(r\"&\\w+;\", \" \", text)\n",
    "\n",
    "    # Keep letters, numbers, spaces, $, %, dots, commas\n",
    "    text = re.sub(r\"[^a-z0-9\\s\\$\\%\\.\\,]\", \" \", text)\n",
    "\n",
    "    # Normalize stock tickers: \"$ aapl\" -> \"$aapl\"\n",
    "    text = re.sub(r\"\\$\\s+([a-z]+)\", r\"$\\1\", text)\n",
    "\n",
    "    # Normalize percentages: \"10  %\" -> \"10%\"\n",
    "    text = re.sub(r\"(\\d+)\\s*%\", r\"\\1%\", text)\n",
    "\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4721624",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 20000   # vocab size\n",
    "max_len = 60      # tweets are short; shorter seq helps\n",
    "\n",
    "# number of labels in the dataset (multi-class)\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<unk>\")\n",
    "tokenizer.fit_on_texts(X_train_clean)\n",
    "\n",
    "X_train_seq = pad_sequences(\n",
    "    tokenizer.texts_to_sequences(X_train_clean),\n",
    "    maxlen=max_len,\n",
    "    padding=\"post\",\n",
    "    truncating=\"post\"\n",
    ")\n",
    "\n",
    "X_val_seq = pad_sequences(\n",
    "    tokenizer.texts_to_sequences(X_val_clean),\n",
    "    maxlen=max_len,\n",
    "    padding=\"post\",\n",
    "    truncating=\"post\"\n",
    ")\n",
    "\n",
    "X_train_seq.shape, X_val_seq.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e044334",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words,\n",
    "                    output_dim=embedding_dim,\n",
    "                    input_length=max_len))\n",
    "\n",
    "# BiLSTM + extra Dense layer\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=False)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))   # multi-class output\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ded9bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 15   # we will stop early if overfitting\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_seq, y_train,\n",
    "    validation_data=(X_val_seq, y_val),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7d9166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw predictions\n",
    "y_val_prob = model.predict(X_val_seq)\n",
    "y_val_pred = np.argmax(y_val_prob, axis=1)\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_val, y_val_pred))\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(y_val, y_val_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81142c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save classification report to file\n",
    "report_text = classification_report(y_val, y_val_pred, digits=4, zero_division=0)\n",
    "\n",
    "with open(\"../results/rnn_classification_report.txt\", \"w\") as f:\n",
    "    f.write(report_text)\n",
    "\n",
    "# Save confusion matrix\n",
    "import numpy as np\n",
    "\n",
    "np.savetxt(\"../results/rnn_confusion_matrix.csv\", confusion_matrix(y_val, y_val_pred), fmt=\"%d\", delimiter=\",\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
